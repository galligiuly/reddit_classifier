{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-reddit_pre-processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGCc_PKjWMpl",
        "colab_type": "text"
      },
      "source": [
        "# Pre processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9aTzSNVU87C",
        "colab_type": "code",
        "outputId": "e3774ad9-638c-4d25-a371-cf353386c5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdMxbJ1UWdC-",
        "colab_type": "code",
        "outputId": "ed40976d-d75d-4055-d5ea-66f292814c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=KxYCV1gmQpTcLiDIcN0lrDP__R9f9KsvS7yp8lfnkkk&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/uwHg5xwUuukbTW1yDSLeC8oYq7b4xkhEMa9WWTKJb4WGEzKNerp4N-8\n",
            "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
            "If you need to use ADC, see:\n",
            "  gcloud auth application-default --help\n",
            "\n",
            "You are now logged in as [galli.giuly@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rubi3r8Wc_6",
        "colab_type": "code",
        "outputId": "c84c8aa3-8ee1-48d9-e8c7-c8be6c51a88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%env GCLOUD_PROJECT=reddit-master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: GCLOUD_PROJECT=reddit-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXxBLQYk0ybz",
        "colab_type": "text"
      },
      "source": [
        "## Standardization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL1cKM_YXG3v",
        "colab_type": "code",
        "outputId": "71c9eec0-551c-40fa-ff5d-95ec03320079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import pickle \n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn import preprocessing\n",
        "from nltk import word_tokenize\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8UHO4ySW4CR",
        "colab_type": "code",
        "outputId": "59d185b8-61d4-4617-dddd-c9832092b831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# importing my final ds\n",
        "\n",
        "!gsutil cp gs://reddit_final_results/reddit_clear_df.pkl ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_final_results/reddit_clear_df.pkl...\n",
            "- [1 files][253.2 MiB/253.2 MiB]                                                \n",
            "Operation completed over 1 objects/253.2 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TFD99xVW36O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_clear_df = pd.read_pickle('reddit_clear_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD2f2KDN1EHP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Encoding the label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdDaMKK2WT1I",
        "colab_type": "text"
      },
      "source": [
        "In case I would need a encoded label to train my final model, I prepare the data set also with `subreddit_id` and I save it as `reddit_clear_encoded_df`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRPho3jlbU6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creting the new df with the encoded column \n",
        "\n",
        "reddit_clear_encoded_df = reddit_clear_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smLZb0tnbeil",
        "colab_type": "code",
        "outputId": "e24e65b7-833b-4fa1-ecf6-825ac2accc18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reddit_clear_encoded_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gaming</td>\n",
              "      <td>honestly share height rest shorties</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gaming</td>\n",
              "      <td>im sure whats funnier way interpreted said act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaming</td>\n",
              "      <td>wait quelaags furysword scaled soft humanity t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gaming</td>\n",
              "      <td>program use make display maps something simila...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gaming</td>\n",
              "      <td>ccleaner turned shit norton makes tool uninsta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subreddit                                               body\n",
              "0    gaming                honestly share height rest shorties\n",
              "1    gaming  im sure whats funnier way interpreted said act...\n",
              "2    gaming  wait quelaags furysword scaled soft humanity t...\n",
              "3    gaming  program use make display maps something simila...\n",
              "4    gaming  ccleaner turned shit norton makes tool uninsta..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-8qbXmC1Dv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode of the label as subreddit_it\n",
        "\n",
        "reddit_clear_encoded_df['subreddit_id'] = reddit_clear_encoded_df['subreddit']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntUj2TVf0pMz",
        "colab_type": "code",
        "outputId": "5a5b43d8-f236-4c32-f92b-d67e7a76ca10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reddit_clear_encoded_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>subreddit_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gaming</td>\n",
              "      <td>honestly share height rest shorties</td>\n",
              "      <td>gaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gaming</td>\n",
              "      <td>im sure whats funnier way interpreted said act...</td>\n",
              "      <td>gaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaming</td>\n",
              "      <td>wait quelaags furysword scaled soft humanity t...</td>\n",
              "      <td>gaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gaming</td>\n",
              "      <td>program use make display maps something simila...</td>\n",
              "      <td>gaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gaming</td>\n",
              "      <td>ccleaner turned shit norton makes tool uninsta...</td>\n",
              "      <td>gaming</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subreddit                                               body subreddit_id\n",
              "0    gaming                honestly share height rest shorties       gaming\n",
              "1    gaming  im sure whats funnier way interpreted said act...       gaming\n",
              "2    gaming  wait quelaags furysword scaled soft humanity t...       gaming\n",
              "3    gaming  program use make display maps something simila...       gaming\n",
              "4    gaming  ccleaner turned shit norton makes tool uninsta...       gaming"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg97VSUj1T6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tICW2CjZ1oKc",
        "colab_type": "code",
        "outputId": "45e14914-52c0-475b-a06e-4c2c95a07bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "le.fit(reddit_clear_encoded_df['subreddit'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcISKw6w1qgP",
        "colab_type": "code",
        "outputId": "64070870-45ef-40d5-a498-1ed088c09e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "list(le.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Fitness',\n",
              " 'atheism',\n",
              " 'aww',\n",
              " 'europe',\n",
              " 'gaming',\n",
              " 'movies',\n",
              " 'nba',\n",
              " 'politics',\n",
              " 'science',\n",
              " 'technology']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnFwpzVe1sP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_clear_encoded_df['subreddit_id'] = le.transform(reddit_clear_encoded_df['subreddit']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drXhM70f1wMD",
        "colab_type": "code",
        "outputId": "5e05a481-fb62-48b6-c08d-90df56462183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reddit_clear_encoded_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>subreddit_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gaming</td>\n",
              "      <td>honestly share height rest shorties</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gaming</td>\n",
              "      <td>im sure whats funnier way interpreted said act...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaming</td>\n",
              "      <td>wait quelaags furysword scaled soft humanity t...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gaming</td>\n",
              "      <td>program use make display maps something simila...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gaming</td>\n",
              "      <td>ccleaner turned shit norton makes tool uninsta...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subreddit                                               body  subreddit_id\n",
              "0    gaming                honestly share height rest shorties             4\n",
              "1    gaming  im sure whats funnier way interpreted said act...             4\n",
              "2    gaming  wait quelaags furysword scaled soft humanity t...             4\n",
              "3    gaming  program use make display maps something simila...             4\n",
              "4    gaming  ccleaner turned shit norton makes tool uninsta...             4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeWmgqmpb99S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_clear_encoded_df.to_pickle('reddit_clear_encoded_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obBFRnyEboMG",
        "colab_type": "code",
        "outputId": "ef40e0dd-cec8-45cc-b58b-8bcdb3f7f52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!gsutil cp reddit_clear_encoded_df.pkl gs://reddit_final_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://reddit_clear_encoded_df.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/265.0 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "\\\n",
            "Operation completed over 1 objects/265.0 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh7Nyvev17CN",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSIOUC_TXoBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = 75000\n",
        "MAX_SEQUENCE_LENGTH = 450\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1j9l0-5Xn_I",
        "colab_type": "code",
        "outputId": "b0b6e865-4fb9-4440-8a92-a698917290b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS,)\n",
        "tokenizer.fit_on_texts(reddit_clear_df['body'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 864049 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUD5G7l_Xn8E",
        "colab_type": "code",
        "outputId": "566e8067-d9b9-4ae8-c068-70b1b7f9b98c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "with open('reddit_tokenizer.pkl', 'wb') as file:\n",
        "    pickle.dump(tokenizer, file)\n",
        "    \n",
        "!gsutil cp reddit_tokenizer.pkl gs://reddit_models/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://reddit_tokenizer.pkl [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/47.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}