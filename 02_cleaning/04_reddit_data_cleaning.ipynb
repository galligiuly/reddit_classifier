{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-reddit_data-cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdnse2qkz_WR",
        "colab_type": "text"
      },
      "source": [
        "# Cleaing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKcyHjpvR-Nh",
        "colab_type": "code",
        "outputId": "b8ee3d85-f5c3-4f9a-f6c4-1e5345e01786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGqOMwVHUpVd",
        "colab_type": "code",
        "outputId": "7869a0d3-0dc7-41be-edc1-22b64d6cf780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=oXGnc2o6ycdC7ce08rXDppK4MlftpOzEheCUF2EwhQ4&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/ugFjk5ZtaR5RGzPO8_UALWn5BQzUaamKJL_fDrBYa_2z4iOLhnA8fmo\n",
            "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
            "If you need to use ADC, see:\n",
            "  gcloud auth application-default --help\n",
            "\n",
            "You are now logged in as [galli.giuly@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1tMoyj9VxGl",
        "colab_type": "code",
        "outputId": "a4a015cc-2431-427b-de8d-4d4d49290858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvqW5MeaUzBY",
        "colab_type": "text"
      },
      "source": [
        "### Pre cleaning with SQL on BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A7Q3zXXUxH1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Pre cleaning filters with SQL\n",
        "\n",
        "The df has been pre \"cleaned\":\n",
        "\n",
        "    no data with body \"deleted\"\n",
        "    no data with body \"removed\"\n",
        "    no data with body \"Removed by reddit in response to a copyright notice.\"\n",
        "    no NAN on body\n",
        "    no empty data on body\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heaCbzQ7VRzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning text frunction for keras model\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "SYMBOLS = re.compile(r\"[^a-zA-Z0-9' ]\")\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text_keras(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "    return text\n",
        "\n",
        "def clean_text_df(df, column):\n",
        "  df[column] = df[column].map(clean_text_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-32WP_HUKh_",
        "colab_type": "code",
        "outputId": "ea4ed073-6c58-4176-ad00-81b4da98b9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# importing my final ds\n",
        "\n",
        "!gsutil cp gs://reddit_final_results/comments_posts.pkl ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_final_results/comments_posts.pkl...\n",
            "- [1 files][374.5 MiB/374.5 MiB]                                                \n",
            "Operation completed over 1 objects/374.5 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDTfjaWJUUZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_df = pd.read_pickle('comments_posts.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF0CcNz4Unv4",
        "colab_type": "code",
        "outputId": "fbbd2d32-9a21-4420-f3cf-e7bd18d22216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reddit_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gaming</td>\n",
              "      <td>honestly share height rest shorties</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gaming</td>\n",
              "      <td>im sure whats funnier way interpreted said act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaming</td>\n",
              "      <td>wait quelaags furysword scaled soft humanity t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gaming</td>\n",
              "      <td>program use make display maps something simila...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gaming</td>\n",
              "      <td>ccleaner turned shit norton makes tool uninsta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subreddit                                               body\n",
              "0    gaming                honestly share height rest shorties\n",
              "1    gaming  im sure whats funnier way interpreted said act...\n",
              "2    gaming  wait quelaags furysword scaled soft humanity t...\n",
              "3    gaming  program use make display maps something simila...\n",
              "4    gaming  ccleaner turned shit norton makes tool uninsta..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5sBHq4uz-JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning my df\n",
        "\n",
        "reddit_df['body'] = reddit_df['body'].apply(clean_text_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yudQt1090M1j",
        "colab_type": "code",
        "outputId": "e4b4d6cc-17fb-48fa-89be-e56ac436f34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reddit_df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1546813</th>\n",
              "      <td>aww</td>\n",
              "      <td>dog attempts get bed back cat claimed removed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546814</th>\n",
              "      <td>aww</td>\n",
              "      <td>r aww official discord join join https discord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546815</th>\n",
              "      <td>aww</td>\n",
              "      <td>knows hes goodest boy removed reddit response ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546816</th>\n",
              "      <td>aww</td>\n",
              "      <td>collection different animal posts today mammal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546817</th>\n",
              "      <td>aww</td>\n",
              "      <td>bestof r aww 2017 awards thread nominations th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        subreddit                                               body\n",
              "1546813       aww  dog attempts get bed back cat claimed removed ...\n",
              "1546814       aww  r aww official discord join join https discord...\n",
              "1546815       aww  knows hes goodest boy removed reddit response ...\n",
              "1546816       aww  collection different animal posts today mammal...\n",
              "1546817       aww  bestof r aww 2017 awards thread nominations th..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UjXyMaPU-89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_df.to_pickle('reddit_clear_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BwT7pPOV0Zr",
        "colab_type": "code",
        "outputId": "d04b0af7-8d1a-4814-9b9a-ce9036fef4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!gsutil cp /content/reddit_clear_df.pkl gs://reddit_final_results/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/reddit_clear_df.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/253.2 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "-\n",
            "Operation completed over 1 objects/253.2 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}