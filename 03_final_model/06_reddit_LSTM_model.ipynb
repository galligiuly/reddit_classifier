{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_reddit_LSTM_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIzuKZlnZEx8",
        "colab_type": "text"
      },
      "source": [
        "# LSTM model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_JP1vp7Y-YP",
        "colab_type": "code",
        "outputId": "4fda018d-903e-4f19-d87a-750eb6e89c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEIDUmxiZcPP",
        "colab_type": "code",
        "outputId": "e4fc8163-c2a9-49d7-c788-437a1d9f6c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=grRJZIi00nlnE2CrsnKpkdQuzTThUWqr-CtGED7U1fo&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/vQHXeU22_RFwzKSDtdGwiwPlJK34hj8zMh-I0JkBAnMEx0GNorH5CZM\n",
            "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
            "If you need to use ADC, see:\n",
            "  gcloud auth application-default --help\n",
            "\n",
            "You are now logged in as [galli.giuly@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRaWQxE_ZmRh",
        "colab_type": "code",
        "outputId": "f3fc0966-df32-4bbb-aeba-3b65c25790c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%env GCLOUD_PROJECT=reddit-master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: GCLOUD_PROJECT=reddit-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2APheCLEZr-S",
        "colab_type": "code",
        "outputId": "5fa786fa-e669-4b3c-9d28-aa93489bfddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import re\n",
        "import plotly.graph_objs as go\n",
        "import chart_studio.plotly as py\n",
        "import cufflinks\n",
        "import plotly.figure_factory as ff\n",
        "import logging\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import log_loss\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from bs4 import BeautifulSoup\n",
        "from plotly.offline import iplot\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
        "from tensorflow import metrics, local_variables_initializer\n",
        "from keras.models import load_model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76qG2_RPZyZh",
        "colab_type": "code",
        "outputId": "b59c6177-3fa2-4fd3-ec61-e15351cbf070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# importing my final ds\n",
        "\n",
        "!gsutil cp gs://reddit_final_results/reddit_clear_df.pkl ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_final_results/reddit_clear_df.pkl...\n",
            "- [1 files][253.2 MiB/253.2 MiB]                                                \n",
            "Operation completed over 1 objects/253.2 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yReUyHOcZzVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_LSTM_df = pd.read_pickle('reddit_clear_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggwn-whwZ5yo",
        "colab_type": "code",
        "outputId": "7c55bc22-9f72-47f2-a5cf-520687cb8ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# importing my final tokenizer\n",
        "\n",
        "!gsutil cp gs://reddit_models/reddit_tokenizer.pkl ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_models/reddit_tokenizer.pkl...\n",
            "- [1 files][ 47.0 MiB/ 47.0 MiB]                                                \n",
            "Operation completed over 1 objects/47.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otymcf72aAjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('reddit_tokenizer.pkl', 'rb') as file:\n",
        "    tokenizer = pkl.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RI_t60fb-kv",
        "colab_type": "text"
      },
      "source": [
        "## Implementing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDc75RMbab7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = 75000\n",
        "MAX_SEQUENCE_LENGTH = 450\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2GxIBaPb5Hv",
        "colab_type": "code",
        "outputId": "d4824ece-47b5-443d-bdf8-74f8b49f3227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = tokenizer.texts_to_sequences(model_LSTM_df['body'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1546818, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_e_M-dCcE_X",
        "colab_type": "code",
        "outputId": "7222a526-db0e-41bc-f7fe-0c1c62b8f820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y = pd.get_dummies(model_LSTM_df['subreddit']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (1546818, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRAnbuaIcJ9w",
        "colab_type": "code",
        "outputId": "43ba0abe-04eb-40e9-f410-03cb93bc58c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "def train_dev_test_split(X, y):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42, stratify=y_val)\n",
        "    return (X_train,\n",
        "                X_val,\n",
        "                X_test,\n",
        "                y_train,\n",
        "                y_val,\n",
        "                y_test)\n",
        "\n",
        "\n",
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = train_dev_test_split(X,Y)\n",
        "\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1082772, 450) (1082772, 10)\n",
            "(232023, 450) (232023, 10)\n",
            "(232023, 450) (232023, 10)\n",
            "CPU times: user 20.7 s, sys: 890 ms, total: 21.6 s\n",
            "Wall time: 21.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgmTmQid2Z61",
        "colab_type": "text"
      },
      "source": [
        "# Training with auc "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiMFyqOrN9yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining auc function\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    auc = metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(local_variables_initializer())\n",
        "    return auc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WTQX11ncJ6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Creating the neural network using Keras' functional api so that\n",
        "# I'm able to inspect each one of the layers later.\n",
        "\n",
        "inpt = Input(shape=(MAX_SEQUENCE_LENGTH,)) \n",
        "emb = Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1])(inpt)\n",
        "dropout = SpatialDropout1D(0.2)(emb)\n",
        "lstm = LSTM(30, dropout=0.2, recurrent_dropout=0.2)(dropout)\n",
        "output = Dense(10, activation='softmax')(lstm)\n",
        "model = Model(inputs =[inpt], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[auc])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N9TXOitcJ3i",
        "colab_type": "code",
        "outputId": "cc008cd9-b68b-49c9-e79a-f50cbad341ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 150\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=1,\n",
        "    min_delta=0.01)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1082772 samples, validate on 232023 samples\n",
            "Epoch 1/10\n",
            "1082772/1082772 [==============================] - 6345s 6ms/step - loss: 1.1251 - auc: 0.8847 - val_loss: 0.9711 - val_auc: 0.9240\n",
            "Epoch 2/10\n",
            "1082772/1082772 [==============================] - 6522s 6ms/step - loss: 0.9286 - auc: 0.9321 - val_loss: 0.9414 - val_auc: 0.9366\n",
            "Epoch 3/10\n",
            "1082772/1082772 [==============================] - 6150s 6ms/step - loss: 0.8710 - auc: 0.9401 - val_loss: 0.9394 - val_auc: 0.9424\n",
            "CPU times: user 7h 19min 40s, sys: 27min 11s, total: 7h 46min 51s\n",
            "Wall time: 5h 16min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G9xhMeYcJ1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('auc_model_lstm_30_batchsize_150_10_subreddits.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeqK8AOYcJyV",
        "colab_type": "code",
        "outputId": "a3492f9c-9c33-4e1f-fe4e-0d23d98aedc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!gsutil cp auc_model_lstm_30_batchsize_150_10_subreddits.h5 gs://reddit_models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://auc_model_lstm_30_batchsize_150_10_subreddits.h5 [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/86.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB5JPGRF5oKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4b24b594-8248-4a0a-ab5b-b9d6bf9d3034"
      },
      "source": [
        "result_auc = model.evaluate(X_test,Y_test)\n",
        "print(print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(result_auc[0],result_auc[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "232023/232023 [==============================] - 1932s 8ms/step\n",
            "Test set\n",
            "  Loss: 0.941\n",
            "  Accuracy: 0.946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyqd4qswRXnw",
        "colab_type": "text"
      },
      "source": [
        "# Training with metric 'accuracy'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUAoI6pSRXNa",
        "colab_type": "code",
        "outputId": "efa382b7-47b4-4f72-dfee-15e1352a6123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Creating the neural network using Keras' functional api so that\n",
        "# I'm able to inspect each one of the layers later.\n",
        "\n",
        "inpt = Input(shape=(MAX_SEQUENCE_LENGTH,)) \n",
        "emb = Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1])(inpt)\n",
        "dropout = SpatialDropout1D(0.2)(emb)\n",
        "lstm = LSTM(30, dropout=0.2, recurrent_dropout=0.2)(dropout)\n",
        "output = Dense(10, activation='softmax')(lstm)\n",
        "model = Model(inputs =[inpt], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 450)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 450, 100)          7500000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 450, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30)                15720     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 7,516,030\n",
            "Trainable params: 7,516,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNeeuiGjRXMD",
        "colab_type": "code",
        "outputId": "5a76c9eb-0a67-414d-83b8-eb345674eaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 150\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=1,\n",
        "    min_delta=0.01)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1082772 samples, validate on 232023 samples\n",
            "Epoch 1/10\n",
            "1082772/1082772 [==============================] - 5560s 5ms/step - loss: 1.1229 - acc: 0.6416 - val_loss: 0.9688 - val_acc: 0.6916\n",
            "Epoch 2/10\n",
            "1082772/1082772 [==============================] - 5552s 5ms/step - loss: 0.9272 - acc: 0.7036 - val_loss: 0.9424 - val_acc: 0.6982\n",
            "Epoch 3/10\n",
            "1082772/1082772 [==============================] - 5535s 5ms/step - loss: 0.8700 - acc: 0.7198 - val_loss: 0.9390 - val_acc: 0.6987\n",
            "CPU times: user 6h 29min 16s, sys: 24min 22s, total: 6h 53min 39s\n",
            "Wall time: 4h 37min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIq7h9tRXK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('accuracy_model_lstm_30_batchsize_150_10_subreddits.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUjVs3WkRXJS",
        "colab_type": "code",
        "outputId": "30175a4c-f0f6-4e52-8f51-f97619242e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!gsutil cp accuracy_model_lstm_30_batchsize_150_10_subreddits.h5 gs://reddit_models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://accuracy_model_lstm_30_batchsize_150_10_subreddits.h5 [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/86.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZvnMCXPRXTN",
        "colab_type": "code",
        "outputId": "2280459a-62d7-4747-caa1-d2ceb3318a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# In case you need to upload the saved model\n",
        "\n",
        "!gsutil cp gs://reddit_models/accuracy_model_lstm_30_batchsize_150_10_subreddits.h5 ."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_models/accuracy_model_lstm_30_batchsize_150_10_subreddits.h5...\n",
            "- [1 files][ 86.0 MiB/ 86.0 MiB]                                                \n",
            "Operation completed over 1 objects/86.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItXQ17zfRXPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_acc = load_model(\"accuracy_model_lstm_30_batchsize_150_10_subreddits.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgcRcOQ6RXEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a2ee812b-3b51-4f41-a71f-e7b8a914673e"
      },
      "source": [
        "result_accr = model_acc.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(result_accr[0],result_accr[1]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "232023/232023 [==============================] - 1856s 8ms/step\n",
            "Test set\n",
            "  Loss: 0.941\n",
            "  Accuracy: 0.698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zHqOWRLxC2p",
        "colab_type": "text"
      },
      "source": [
        "# Testing the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HQOQzXAKUAB",
        "colab_type": "text"
      },
      "source": [
        "#### best model: auc_model_lstm_30_batchsize_150_10_subreddits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Enakde5Cao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "07d9ef53-ff74-4916-d278-c7c62786ce4d"
      },
      "source": [
        "# In case you need to upload the saved model\n",
        "\n",
        "!gsutil cp gs://reddit_models/auc_model_lstm_30_batchsize_150_10_subreddits.h5 ."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_models/auc_model_lstm_30_batchsize_150_10_subreddits.h5...\n",
            "- [1 files][ 86.0 MiB/ 86.0 MiB]                                                \n",
            "Operation completed over 1 objects/86.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_vYvx2V5hSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dependencies = {\n",
        "    'auc': auc\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLebv7l95CPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5b3d3cf7-b3aa-405d-ad44-7eb8947190c1"
      },
      "source": [
        "model = load_model(\"auc_model_lstm_30_batchsize_150_10_subreddits.h5\", custom_objects=dependencies)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up4VThdhvDki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_decoder(subreddit):\n",
        "    dict_labels = {\n",
        "        0:\"Fitness\",\n",
        "        1:\"atheism\",\n",
        "        2:\"aww\",\n",
        "        3:\"europe\",\n",
        "        4:\"gaming\",\n",
        "        5:\"movies\",\n",
        "        6:\"nba\",\n",
        "        7:\"politics\",\n",
        "        8:\"science\",\n",
        "        9:\"technology\"\n",
        "    }\n",
        "    \n",
        "    return dict_labels[subreddit]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Ea5aNor-wF",
        "colab_type": "code",
        "outputId": "536571e2-838a-41b0-cba2-2157ddb4c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "text = input(\"Please, enter the text of your blog: \") \n",
        "print(\"\")\n",
        "print(\"Text correctly entered, I'll give you that subreddit in a minute\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, enter the text of your blog: Multi-label classification originated from the investigation of text categorisation problem, where each document may belong to several predefined topics simultaneously. Multi-label classification of textual data is an important problem. Examples range from news articles to emails. For instance, this can be employed to find the genres that a movie belongs to, based on the summary of its plot.\n",
            "\n",
            "Text correctly entered, I'll give you that subreddit in a minute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJEdzFrfvLO4",
        "colab_type": "code",
        "outputId": "2592b9cb-4cc6-4233-b1e3-d10fd24d2cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_NB_WORDS = 75000\n",
        "MAX_SEQUENCE_LENGTH = 450\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "X = tokenizer.texts_to_sequences([text])\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0S6eE5Dr-tR",
        "colab_type": "code",
        "outputId": "ad88368f-6b34-4509-c710-8ba2a50e7891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = model.predict(X)\n",
        "\n",
        "def convert_to_cat(arr):\n",
        "    biggest = 0\n",
        "    for x in range(0, len(arr)):\n",
        "        if arr[x] > arr[biggest]:\n",
        "            biggest = x\n",
        "    return biggest\n",
        "\n",
        "category = [label_decoder(convert_to_cat(x)) for x in result]\n",
        "\n",
        "print(\"you should publish your text into the sureddit: \", category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you should publish your text into the sureddit:  ['technology']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}