{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proyect_testing_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5FpHIeoCMsW",
        "colab_type": "text"
      },
      "source": [
        "# Project testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkyIJJvLBxcG",
        "colab_type": "code",
        "outputId": "84d9725b-3a73-4217-d053-b72ab60bd2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkQ_JUZ7Cc7X",
        "colab_type": "code",
        "outputId": "5c8bff9c-dd6f-4ef3-c11e-5827805e8745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=H32pyw_3sw5BzmURr4k8-uh-xSd1ORHx2AEgPvqpQuk&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/vwGjoX2cFXTqUPmmQLkEqefMHfp8BXs4j_LeKQmTO2L_ja1ppV-qeM4\n",
            "\n",
            "You are now logged in as [galli.giuly@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmHWk97rCrmm",
        "colab_type": "code",
        "outputId": "f3551d90-2982-43a0-b056-6a4faa4dcea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%env GCLOUD_PROJECT=reddit-master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: GCLOUD_PROJECT=reddit-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siW2dGCmCxI-",
        "colab_type": "code",
        "outputId": "a1a51d44-ba68-45b0-fc5c-7d7c1ad685b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import re\n",
        "import plotly.graph_objs as go\n",
        "import chart_studio.plotly as py\n",
        "import cufflinks\n",
        "import plotly.figure_factory as ff\n",
        "import logging\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import log_loss\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from bs4 import BeautifulSoup\n",
        "from plotly.offline import iplot\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
        "from tensorflow import metrics, local_variables_initializer\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zHqOWRLxC2p",
        "colab_type": "text"
      },
      "source": [
        "### Downloading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFDK9Un46xBR",
        "colab_type": "code",
        "outputId": "a8f09012-eff5-4127-fccc-71481c7fd8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLOe5cHBcJvM",
        "colab_type": "code",
        "outputId": "7292def4-a9a1-401a-a89b-e6355e6520bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!gsutil cp gs://reddit_models/accuracy_model_lstm_30_batchsize_150_10_subreddits.h5 ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_models/accuracy_model_lstm_30_batchsize_150_10_subreddits.h5...\n",
            "| [1 files][ 86.0 MiB/ 86.0 MiB]                                                \n",
            "Operation completed over 1 objects/86.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2HXzHgT5kD9",
        "colab_type": "code",
        "outputId": "8185b7a5-9887-44be-c5d3-1b9507a5d944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "model = load_model(\"accuracy_model_lstm_30_batchsize_150_10_subreddits.h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct7MYgkAEgW3",
        "colab_type": "code",
        "outputId": "8826c139-5edf-44ed-b8b9-8d546684d0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# importing my final tokenizer\n",
        "\n",
        "!gsutil cp gs://reddit_models/reddit_tokenizer.pkl ."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_models/reddit_tokenizer.pkl...\n",
            "| [1 files][ 47.0 MiB/ 47.0 MiB]                                                \n",
            "Operation completed over 1 objects/47.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlMZr9HeEgTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('reddit_tokenizer.pkl', 'rb') as file:\n",
        "    tokenizer = pkl.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up4VThdhvDki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_decoder(subreddit):\n",
        "    dict_labels = {\n",
        "        0:\"Fitness\",\n",
        "        1:\"atheism\",\n",
        "        2:\"aww\",\n",
        "        3:\"europe\",\n",
        "        4:\"gaming\",\n",
        "        5:\"movies\",\n",
        "        6:\"nba\",\n",
        "        7:\"politics\",\n",
        "        8:\"science\",\n",
        "        9:\"technology\"\n",
        "    }\n",
        "    \n",
        "    return dict_labels[subreddit]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoIR9169Di_z",
        "colab_type": "text"
      },
      "source": [
        "# How test my model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS3cXnQ5Do_g",
        "colab_type": "text"
      },
      "source": [
        "Here below you can find the steps to follow for testing the model:\n",
        "\n",
        "    \n",
        "\n",
        "*   go to reddit.com and search for one of the following subreddits:\n",
        "\n",
        "        Fitness\n",
        "        atheism\n",
        "        aww\n",
        "        europe\n",
        "        gaming\n",
        "        movies\n",
        "        nba\n",
        "        politics\n",
        "        science\n",
        "        technology\n",
        "\n",
        "*   copy the text you want to test\n",
        "\n",
        "*   go to \"Step 1\" and paste the text once you have executed the correspoding row\n",
        "\n",
        "*   Execute step 2\n",
        "\n",
        "*   Execute step 3 for the result\n",
        "\n",
        "**Final test**: is the suggestion of my model exactly the subreddit where you picked the text?!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNTcTbjuEN0_",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: copy the text or post you what to publush"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Ea5aNor-wF",
        "colab_type": "code",
        "outputId": "4363120c-2449-4229-f590-7f102bfee3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "text = input(\"Please, enter the text of your blog: \") \n",
        "print(\"\")\n",
        "print(\"Text correctly entered, I'll give you that subreddit in a minute\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, enter the text of your blog: The Laboratory for Molecular Biology (LMB), clad in glass the color of sea ice, rises like a futuristic factory above the rapeseed fields of Cambridge, U.K. It is the crown jewel of the U.K. Medical Research Council, a storied government lab that has garnered more than a dozen Nobel Prizes. One of the first came in 1962 after LMB researchers, having pioneered x-ray crystallography, used the technique to decipher the first atomic structures for proteins—those of myoglobin and hemoglobin, which carry oxygen in muscle tissue and blood. X-ray crystallography has dominated structural biology ever since, but it has an Achilles’ heel: Some proteins just can’t be coaxed to form crystals, which scatter x-rays to reveal structure.\n",
            "\n",
            "Text correctly entered, I'll give you that subreddit in a minute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySiRjUO0ERca",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: processing the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJEdzFrfvLO4",
        "colab_type": "code",
        "outputId": "ac54435e-2713-4619-e2c0-958e5725ae86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_NB_WORDS = 75000\n",
        "MAX_SEQUENCE_LENGTH = 450\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "X = tokenizer.texts_to_sequences([text])\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4yw3HfnETYe",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: get the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0S6eE5Dr-tR",
        "colab_type": "code",
        "outputId": "9be37087-775f-4207-b013-eaf52cff0723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = model.predict(X)\n",
        "\n",
        "def convert_to_cat(arr):\n",
        "    biggest = 0\n",
        "    for x in range(0, len(arr)):\n",
        "        if arr[x] > arr[biggest]:\n",
        "            biggest = x\n",
        "    return biggest\n",
        "\n",
        "category = [label_decoder(convert_to_cat(x)) for x in result]\n",
        "\n",
        "print(\"you should publish your text into the sureddit: \", category)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you should publish your text into the sureddit:  ['science']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}